{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. preparing \n",
    "## a. importing lib and data, data preparation and formatting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "import json\n",
    "import gc\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import operator\n",
    "import unidecode\n",
    "from itertools import islice\n",
    "\n",
    "def jl_to_list(fname):\n",
    "    output = []\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        for line in f:\n",
    "            output.append(json.loads(line))\n",
    "    return output\n",
    "\n",
    "#######################################################\n",
    "\n",
    "item_data = jl_to_list('item_data.jl.gz')\n",
    "metadata = {x['item_id']:x for x in item_data}\n",
    "all_items = list(metadata.keys())\n",
    "\n",
    "#######################################################\n",
    "\n",
    "samples = False\n",
    "rows = jl_to_list('train_dataset.jl.gz')\n",
    "print(len(rows))\n",
    "if samples:\n",
    "    rows = rows[:samples]\n",
    "    \n",
    "#######################################################\n",
    "\n",
    "metadata_domain_quantity =defaultdict(int)\n",
    "metadata_domain_id_with_item = defaultdict(lambda: defaultdict(int))\n",
    "metadata_domain_item_words = defaultdict(lambda: defaultdict(lambda: []))\n",
    "metadata_domain_words = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "for x in tqdm(item_data):\n",
    "    metadata_domain_id_with_item[x['domain_id']][x['item_id']]=0   \n",
    "    words = x['title'].split()\n",
    "    \n",
    "    for w in words:\n",
    "        if (len(w)>3) & (unidecode.unidecode(w).upper() not in metadata_domain_item_words[x['domain_id']][x['item_id']]):\n",
    "            metadata_domain_item_words[x['domain_id']][x['item_id']].append(unidecode.unidecode(w).upper())\n",
    "        if (len(w)>3):\n",
    "            metadata_domain_words[x['domain_id']][unidecode.unidecode(w).upper()]+=1\n",
    "\n",
    "\n",
    "for row in tqdm(rows):\n",
    "    viewed = [ev['event_info'] for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "    for item in viewed:\n",
    "        domain = metadata[item]['domain_id']\n",
    "        metadata_domain_id_with_item[domain][item]+=1\n",
    "        \n",
    "    metadata_domain_quantity[metadata[row['item_bought']]['domain_id']]+=1\n",
    "     \n",
    "metadata_domain_quantity = dict(sorted(metadata_domain_quantity.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "lim_gr = 0.98\n",
    "sum_item=0\n",
    "sum_all_items = sum(metadata_domain_quantity.values())\n",
    "list_domain_to_study = []\n",
    "for dom, n_item_bought in metadata_domain_quantity.items():\n",
    "    sum_item+=n_item_bought\n",
    "    list_domain_to_study.append(dom)\n",
    "    if float(sum_item)/float(sum_all_items)>lim_gr:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. b. scoring metric and helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# score metric\n",
    "def ndcg(y_pred, y_true):\n",
    "\n",
    "    ncdg_li = []\n",
    "    for y_pred_el, y_true_el in zip(y_pred, y_true):\n",
    "        dcg = 0\n",
    "        pos=1\n",
    "        uniq_ypred = []\n",
    "        for y_pred_el_pos in y_pred_el:\n",
    "            if y_pred_el_pos not in uniq_ypred:\n",
    "                uniq_ypred.append(y_pred_el_pos)                \n",
    "                dcg+=relevance(y_true_el, y_pred_el_pos)/(math.log(1+pos))\n",
    "            else:\n",
    "                dcg+=0\n",
    "            \n",
    "            pos+=1\n",
    "            \n",
    "        idcg = 22.42461597\n",
    "        ncdg_li.append(dcg/idcg)\n",
    "    \n",
    "    return ncdg_li\n",
    " \n",
    "def relevance(y, y_hat):\n",
    "    \n",
    "    domain_y = metadata[y]['domain_id']\n",
    "    domain_y_hat = metadata[y_hat]['domain_id']\n",
    "    \n",
    "    if y == y_hat:\n",
    "        return 12\n",
    "    elif domain_y == domain_y_hat:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "#######################################################\n",
    "# probably exist better \n",
    "from datetime import datetime\n",
    "\n",
    "def diff_date(d1_string, d2_string):\n",
    "    \n",
    "    d1_date= datetime(year = int(d1_string[0:4]), month=int(d1_string[5:7]), day =int(d1_string[8:10]), hour = int(d1_string[11:13]), \n",
    "                               minute = int(d1_string[14:16]), second = int(d1_string[17:19]))\n",
    "\n",
    "    d2_date= datetime(year = int(d2_string[0:4]), month=int(d2_string[5:7]), day =int(d2_string[8:10]), hour = int(d2_string[11:13]), \n",
    "                               minute = int(d2_string[14:16]), second = int(d2_string[17:19]))\n",
    "\n",
    "    return (d2_date-d1_date).total_seconds()/(3600*24)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.c. some helper functions\n",
    "here, trying to take into account the words from search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_style : \"most common\", \"last search\"\n",
    "def relleno_search_based(row, search_style):\n",
    "\n",
    "    search = [ev for ev in row['user_history'] if ev['event_type'] == 'search']\n",
    "\n",
    "    all_words_searched = Counter()\n",
    "    words_last_search = []\n",
    "    words_most_common_search = []\n",
    "    \n",
    "    if len(search)>0:\n",
    "\n",
    "        for ev in search:\n",
    "            all_words_searched[ev['event_info']]+=1\n",
    "            words_last_search = ev['event_info'].split()\n",
    "\n",
    "        if search_style == \"most common\":\n",
    "            words_studied = all_words_searched.most_common(1)[0][0].split()\n",
    "        elif search_style == \"last search\":\n",
    "            words_studied = words_last_search\n",
    "        all_domain_words_relation = defaultdict(int)\n",
    "\n",
    "        for dom in list_domain_to_study:\n",
    "\n",
    "            value_words = 0\n",
    "            \n",
    "            for word in words_studied:\n",
    "                \n",
    "                if len(word)>3:\n",
    "                    \n",
    "                    word_upper = unidecode.unidecode(word).upper()\n",
    "                    if (word_upper in metadata_domain_words[dom].keys()) or (word_upper[:len(word_upper)-1] in metadata_domain_words[dom].keys()) or (word_upper[:len(word_upper)-2] in metadata_domain_words[dom].keys()):\n",
    "                        value_words+= metadata_domain_words[dom][word_upper]\n",
    "\n",
    "              \n",
    "            all_domain_words_relation[dom]+=value_words\n",
    "\n",
    "        \n",
    "        all_domain_words_relation = dict(sorted(all_domain_words_relation.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "        first_dom = list(islice(all_domain_words_relation, 1))[0]  \n",
    "        list_items = defaultdict(int)\n",
    "        \n",
    "        for item_id, words in metadata_domain_item_words[first_dom].items():\n",
    "            \n",
    "            for word in words_studied: \n",
    "                if len(word)>3:\n",
    "                    word_upper = unidecode.unidecode(word).upper()\n",
    "                    if (word_upper in words) or (word_upper[:len(word_upper)-1] in words) or  (word_upper[:len(word_upper)-2] in words):\n",
    "                        list_items[item_id]+=1\n",
    "        \n",
    "        if len(list_items)!=0:\n",
    "            list_items = dict(sorted(list_items.items(), key=lambda item: item[1], reverse = True))        \n",
    "           \n",
    "        else:\n",
    "            list_items = dict(sorted(metadata_domain_id_with_item[first_dom].items(), key=lambda item: item[1], reverse = True))      \n",
    " \n",
    "        return [item[0] for item in list(islice(list_items.items(), 10))[:10]]\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, generating the various ranks, here, through the use of pandas dataframe ==>> not the best way to handle data, may be done probably with less lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which produces the variables that will be used to predict the domain\n",
    "def df_rows(rows, with_target=False):\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    data_domains = []\n",
    "    data_items=[]\n",
    "    for row in tqdm(rows):\n",
    "\n",
    "\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "        ### search part\n",
    "        search = [ev for ev in row['user_history'] if ev['event_type'] == 'search']\n",
    "\n",
    "        all_words_searched = Counter()\n",
    "        words_last_search = []\n",
    "        words_most_common_search = []\n",
    "        metadata_domain_info_sorted ={}\n",
    "        \n",
    "        if len(search)>0:\n",
    "        \n",
    "\n",
    "            for ev in search:\n",
    "                all_words_searched[ev['event_info']]+=1\n",
    "                words_last_search = ev['event_info'].split()\n",
    "                \n",
    "            search_style = \"most common\"\n",
    "            if search_style == \"most common\":\n",
    "                words_studied = all_words_searched.most_common(1)[0][0].split()\n",
    "            elif search_style == \"last search\":\n",
    "                words_studied = words_last_search\n",
    "            all_domain_words_relation = defaultdict(int)\n",
    "\n",
    "            for dom in list_domain_to_study:\n",
    "\n",
    "                value_words = 0\n",
    "            \n",
    "                for word in words_studied:\n",
    "                \n",
    "                    if len(word)>3:\n",
    "                    \n",
    "                        word_upper = unidecode.unidecode(word).upper()\n",
    "                        if (word_upper in metadata_domain_words[dom].keys()) or (word_upper[:len(word_upper)-1] in metadata_domain_words[dom].keys()) or (word_upper[:len(word_upper)-2] in metadata_domain_words[dom].keys()):\n",
    "                            value_words+= metadata_domain_words[dom][word_upper]\n",
    "\n",
    "              \n",
    "                all_domain_words_relation[dom]+=value_words\n",
    "\n",
    "        \n",
    "            metadata_domain_info_sorted = dict(sorted(all_domain_words_relation.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "        \n",
    "        ### viewed part\n",
    "        viewed = [ev for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "        if len(viewed)==0:  \n",
    "            continue\n",
    "            \n",
    "        domains_list = defaultdict(int)\n",
    "        item_list_by_domains_list = defaultdict(lambda: defaultdict(lambda:[]))\n",
    "\n",
    "        for item in viewed:\n",
    "            if metadata[item['event_info']]['domain_id']!=None:\n",
    "                domains_list[metadata[item['event_info']]['domain_id']]+=1\n",
    "                item_list_by_domains_list[metadata[item['event_info']]['domain_id']][item['event_info']].append(item['event_timestamp'])\n",
    "\n",
    "        if len(domains_list)==0:  \n",
    "            continue\n",
    "            \n",
    "        data_domain = []\n",
    "        \n",
    "        for dom,dom_info in item_list_by_domains_list.items():\n",
    "\n",
    "            dom_val_search = 0\n",
    "            \n",
    "            if dom in metadata_domain_info_sorted.keys():\n",
    "                dom_val_search = metadata_domain_info_sorted[dom]\n",
    "                \n",
    "            if with_target:\n",
    "                if metadata[row['item_bought']]['domain_id'] == dom:    \n",
    "                    in_domain_only_from_item_bought = 1\n",
    "                else:\n",
    "                    in_domain_only_from_item_bought = 0\n",
    "            \n",
    "                if metadata[row['item_bought']]['domain_id'] in item_list_by_domains_list.keys():    \n",
    "                    in_1domain_of_domain_list = 1\n",
    "                else:\n",
    "                    in_1domain_of_domain_list = 0\n",
    "            else:\n",
    "                in_domain_only_from_item_bought =0\n",
    "                in_1domain_of_domain_list =0\n",
    "                \n",
    "                \n",
    "                \n",
    "            data_item=[]\n",
    "            in_domain_and_item_bought = 0\n",
    "            for item, item_event in dom_info.items():\n",
    "\n",
    "                if with_target:\n",
    "                    if row['item_bought'] == item:\n",
    "                        item_bought = 1\n",
    "                        in_domain_and_item_bought =1\n",
    "                        j+=1\n",
    "                    else:\n",
    "                        item_bought = 0\n",
    "                else:\n",
    "                    item_bought =0\n",
    "                    in_domain_and_item_bought =0\n",
    "\n",
    "                data_item.append([item, len(item_event), item_event[len(item_event)-1],item_bought, dom, i, 0,\n",
    "                                 metadata[item]['title'], metadata[item]['price'],\n",
    "                                 metadata[item]['category_id']])\n",
    "\n",
    "            sort_item_by_item = sorted(data_item, key = lambda x:(-x[0]))\n",
    "            sort_item_by_nb_event = sorted(sort_item_by_item, key = lambda x:(-x[1]))\n",
    "            max_nb_event = sort_item_by_nb_event[0][1]\n",
    "            sum_nb_event =0\n",
    "            prom_nb_event=0\n",
    "            for ev_ in sort_item_by_nb_event:\n",
    "                sum_nb_event += ev_[1]\n",
    "            prom_nb_event = sum_nb_event/len(sort_item_by_nb_event)\n",
    "            #max_nb_event =sum_nb_event\n",
    "            sort_item_by_date_event = sorted(data_item, key = lambda x:(x[2]), reverse=True)\n",
    "            last_date= sort_item_by_date_event[0][2]   \n",
    "            first_date = sort_item_by_date_event[len(sort_item_by_date_event)-1][2]\n",
    "            time_domain= diff_date(first_date, last_date)\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "            data_domain.append([i, dom, len(item_list_by_domains_list.keys()), len(data_item),\n",
    "                                max_nb_event,last_date, in_domain_and_item_bought,\n",
    "                                in_domain_only_from_item_bought, in_1domain_of_domain_list, 0,\n",
    "                               time_domain, dom_val_search])\n",
    "            data_items = data_items + data_item\n",
    "        \n",
    "        # rank by dom_val_search\n",
    "        sort_domain_by_dom_val_search = sorted(data_domain, key = lambda x:(-x[11]))\n",
    "        r = 0\n",
    "        sort_domain_by_dom_val_search_with_rank = []\n",
    "        for el in sort_domain_by_dom_val_search:\n",
    "            r+=1 \n",
    "            sort_domain_by_dom_val_search_with_rank.append(el+[ r])\n",
    "            \n",
    "            \n",
    "            \n",
    "        # rank by last date\n",
    "        sort_domain_by_date_event = sorted(sort_domain_by_dom_val_search_with_rank, key = lambda x:(x[5]), reverse=True)\n",
    "        max_time= diff_date(sort_domain_by_date_event[len(sort_domain_by_date_event)-1][5], sort_domain_by_date_event[0][5])\n",
    "        r = 0\n",
    "        sort_domain_by_date_event_with_rank = []\n",
    "        for el in sort_domain_by_date_event:\n",
    "            r+=1 \n",
    "            sort_domain_by_date_event_with_rank.append(el+[max_time, r])\n",
    "\n",
    "        # rank by nb event of 1 item\n",
    "        sort_domain_by_nb_event = sorted(sort_domain_by_date_event_with_rank, key = lambda x:(-x[4]))\n",
    "        r=0\n",
    "        sort_domain_by_nb_event_with_rank=[]\n",
    "        for el in sort_domain_by_nb_event:\n",
    "            r+=1        \n",
    "            sort_domain_by_nb_event_with_rank.append(el+[r])\n",
    "\n",
    "\n",
    "        # rank by qty item\n",
    "        sort_domain_by_qty_item = sorted(sort_domain_by_nb_event_with_rank, key = lambda x:(-x[3]))\n",
    "        r=0\n",
    "        sort_domain_by_qty_item_with_rank=[]\n",
    "        for el in sort_domain_by_qty_item:\n",
    "            r+=1        \n",
    "            sort_domain_by_qty_item_with_rank.append(el+[r])            \n",
    "\n",
    "\n",
    "        data_domains =data_domains+sort_domain_by_qty_item_with_rank\n",
    "\n",
    "\n",
    "\n",
    "    return (pd.DataFrame(data_domains, columns=['i', 'dom name', 'qty domain history', 'qty item viewed', \n",
    "                                                'max nb event of 1 item', 'last date', \n",
    "                                               'item bought in this domain', 'in domain only from item bought', \n",
    "                                                'in_1domain_of_domain_list','no view','time_domain', 'dom_val_search',\n",
    "                                                'rank by dom val search', 'max time',\n",
    "                                                'rank by last date', 'rank by max nb event of 1 item', 'rank by qty item'\n",
    "                                                ]),\n",
    "            pd.DataFrame(data_items, columns = ['item', 'len(item_event)', 'last_event',\n",
    "                                                    'is item bought', 'dom name', 'i', 'no view',\n",
    "                                               'title', 'price', 'category id']))\n",
    "\n",
    "   \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. calibration of the logistic regression model\n",
    "the idea was to use this model, to predict the next domain, based on the ranks values of each domain candidates\n",
    "\n",
    "## a. importing lib, generating train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e1980d6c2a45b6ab2e47228b5bea46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afda89d3c55a4e639fe9120e65f710f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading the data to build the model to predict the domain\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "n = 10000\n",
    "\n",
    "X_train, X_test  = train_test_split(rows, test_size=0.5, random_state=523)\n",
    "df_train_domains, df_train_items = df_rows(X_train[:n], True)\n",
    "df_train_domains = df_train_domains[df_train_domains['in_1domain_of_domain_list'] ==1]\n",
    "df_test_domains, df_test_items = df_rows(X_test[:n], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. selecting the feature, fitting, calibrating, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.79\n",
      "[[21779  5224]\n",
      " [ 1353  3484]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87     27003\n",
      "           1       0.40      0.72      0.51      4837\n",
      "\n",
      "    accuracy                           0.79     31840\n",
      "   macro avg       0.67      0.76      0.69     31840\n",
      "weighted avg       0.86      0.79      0.81     31840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning the model \n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "X = df_train_domains[['rank by last date', \n",
    "                      'rank by max nb event of 1 item', 'rank by qty item', 'rank by dom val search']]\n",
    "y = df_train_domains['in domain only from item bought']\n",
    "\n",
    "X_test_values = df_test_domains[[ 'rank by last date', \n",
    "                                 'rank by max nb event of 1 item', 'rank by qty item', 'rank by dom val search']]\n",
    "y_test = df_test_domains['in domain only from item bought']\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C = 1.0)\n",
    "logreg.fit(X, y)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test_values)\n",
    "y_pred_p = logreg.predict_proba(X_test_values)\n",
    "\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test_values, y_test)))\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main : getting data from user history of test set, making the prediction, computing the ncdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bf41c1edd04d379a5dd938633c6f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ncdg : 0.25154042051587294\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "y_true_ncdg = [row['item_bought'] for row in X_test[:n]]\n",
    "y_pred_ncdg =[]\n",
    "\n",
    "df_test_domains_ncdg_calc = pd.DataFrame(df_test_domains)\n",
    "df_test_domains_ncdg_calc[['y_pred_p is not dom','y_pred_p is dom'] ]= y_pred_p\n",
    "\n",
    "for i in tqdm(range(1,n+1)):\n",
    "\n",
    "    domains = df_test_domains_ncdg_calc[df_test_domains_ncdg_calc['i']==i]\n",
    "    items = df_test_items[df_test_items['i']==i]\n",
    "    row = X_test[i-1]\n",
    "    n_viewed = len([ev for ev in row['user_history'] if ev['event_type'] == 'view'])\n",
    "    n_search = len([ev for ev in row['user_history'] if ev['event_type'] == 'search']) \n",
    "     \n",
    "    if (n_viewed/(n_viewed+n_search)<=0.05) or (len(domains)==0): \n",
    "        \n",
    "        rellenos = relleno_search_based(row, \"most common\")    \n",
    "        if rellenos == None:       \n",
    "            rellenos = random.choices(all_items, k=10) \n",
    "        if len(rellenos)<10:\n",
    "            rellenos = rellenos + random.choices(all_items, k=10-len(rellenos)) \n",
    "            \n",
    "        y_pred_ncdg.append(rellenos)\n",
    " \n",
    "    else:\n",
    "\n",
    "        recom=[]\n",
    "        domains_list_sorted = domains.sort_values(by=['y_pred_p is dom'], ascending=False) \n",
    "        first_dom = domains_list_sorted['dom name'].values[0]\n",
    "               \n",
    "        #item_in_first_domain = items[items['dom name'] == first_dom].sort_values(by=['len(item_event)'], ascending=False)\n",
    "        item_in_first_domain = items[items['dom name'] == first_dom].sort_values(by=['last_event'], ascending=False)                \n",
    "        recom1 = []\n",
    "\n",
    "        for item in item_in_first_domain['item']:\n",
    "            recom1.append(item)        \n",
    "        \n",
    "        if len(domains_list_sorted)>1:\n",
    "            sec_dom = domains_list_sorted['dom name'].values[1]\n",
    "\n",
    "            item_in_sec_domain = items[items['dom name'] == sec_dom].sort_values(by=['len(item_event)'], ascending=False)            \n",
    "            #item_in_sec_domain = items[items['dom name'] == sec_dom].sort_values(by=['last_event'], ascending=False)    \n",
    "                \n",
    "            recom2 = []\n",
    "            for item in item_in_sec_domain['item']:\n",
    "                if item not in recom1:\n",
    "                    recom2.append(item) \n",
    "             \n",
    "            if len(recom1)<6:\n",
    "                recom=recom1+recom2\n",
    "            else:\n",
    "                recom = recom1[:5]+recom2\n",
    "\n",
    "        else:\n",
    "                        \n",
    "            recom = recom1\n",
    "                    \n",
    "        if len(recom)>=10:\n",
    "            recom = recom[:10]\n",
    "        else:\n",
    "            k = 10 - len(recom)\n",
    "            #relleno = random.choices(list(metadata_domain_id_with_item[first_dom].keys()), k=k)   \n",
    "            relleno = sorted(metadata_domain_id_with_item[first_dom].items(), key=lambda item: item[1], reverse = True)[:k]\n",
    "            relleno = [r[0] for r in relleno]   \n",
    "            recom = recom + relleno \n",
    "\n",
    "            \n",
    "            if recom == None:\n",
    "                recom = random.choices(all_items, k=10) \n",
    "            if len(recom)<10:\n",
    "                recom = recom + random.choices(all_items, k=10-len(recom)) \n",
    "            \n",
    "        y_pred_ncdg.append(recom)\n",
    "\n",
    "\n",
    "score = ndcg(y_pred_ncdg, y_true_ncdg)\n",
    "score = sum(score)/len(score)\n",
    "print(\"ncdg :\",score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python38664bit0b6cf5f9081b4010be08c4eb59356c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
